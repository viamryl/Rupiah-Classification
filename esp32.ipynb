{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp_model\\assets\n",
      "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "2023-10-16 00:17:10,649 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "2023-10-16 00:17:10,651 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2023-10-16 00:17:11,561 - INFO - Signatures found in model: [serving_default].\n",
      "2023-10-16 00:17:11,561 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2023-10-16 00:17:11,561 - INFO - Output names: ['dense_5']\n",
      "2023-10-16 00:17:11,730 - INFO - Using tensorflow=2.12.0, onnx=1.14.1, tf2onnx=1.15.1/37820d\n",
      "2023-10-16 00:17:11,730 - INFO - Using opset <onnx, 15>\n",
      "2023-10-16 00:17:11,744 - INFO - Computed 0 values for constant folding\n",
      "2023-10-16 00:17:11,772 - INFO - Optimizing ONNX model\n",
      "2023-10-16 00:17:11,836 - INFO - After optimization: Cast -1 (1->0), Identity -2 (2->0), Transpose -14 (16->2)\n",
      "2023-10-16 00:17:11,840 - INFO - \n",
      "2023-10-16 00:17:11,840 - INFO - Successfully converted TensorFlow model tmp_model to ONNX\n",
      "2023-10-16 00:17:11,840 - INFO - Model inputs: ['conv2d_8_input']\n",
      "2023-10-16 00:17:11,840 - INFO - Model outputs: ['dense_5']\n",
      "2023-10-16 00:17:11,840 - INFO - ONNX model is saved at cnn_v2.onnx\n",
      "'zip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"cnn_v2.h5\")\n",
    "tf.saved_model.save(model, \"tmp_model\")\n",
    "!python -m tf2onnx.convert --saved-model tmp_model --output \"cnn_v2.onnx\"\n",
    "!zip -r /content/tmp_model.zip /content/tmp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\VA\\AppData\\Local\\Temp\\tmpmc97u8z7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\VA\\AppData\\Local\\Temp\\tmpmc97u8z7\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the Keras model\n",
    "model = tf.keras.models.load_model('cnn_v2.h5')\n",
    "\n",
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model\n",
    "with open('converted_model_cnnv2.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
